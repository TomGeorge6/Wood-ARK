#!/usr/bin/env python3
"""
æµ‹è¯•å†å²æ•°æ®ä¸‹è½½åŠŸèƒ½
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.utils import load_config, setup_logging
from src.fetcher import DataFetcher


def test_download_history():
    """æµ‹è¯•ä¸‹è½½å†å²æ•°æ®"""
    
    # åŠ è½½é…ç½®
    config = load_config("config.yaml")
    setup_logging(config)
    
    # åˆå§‹åŒ– Fetcher
    fetcher = DataFetcher(config=config)
    
    print("\nğŸ“¥ æµ‹è¯•ä¸‹è½½ ARKK æœ€è¿‘ 90 å¤©å†å²æ•°æ®...")
    
    # ä¸‹è½½å†å²æ•°æ®
    count = fetcher.download_historical_data("ARKK", days=90)
    
    print(f"\nâœ… ä¸‹è½½å®Œæˆ: æ–°å¢ {count} ä¸ªæ–‡ä»¶")
    
    # æ£€æŸ¥æ–‡ä»¶
    holdings_dir = Path("./data/holdings/ARKK")
    if holdings_dir.exists():
        files = sorted(holdings_dir.glob("*.csv"))
        print(f"\nğŸ“Š ARKK ç›®å½•ä¸‹å…±æœ‰ {len(files)} ä¸ªæ–‡ä»¶")
        
        if files:
            print(f"\næœ€æ—©: {files[0].stem}")
            print(f"æœ€æ™š: {files[-1].stem}")
    
    print("\nğŸ§¹ æµ‹è¯•æ¸…ç†è¿‡æœŸæ•°æ®...")
    
    # æµ‹è¯•æ¸…ç†ï¼ˆä¿ç•™ 90 å¤©ï¼‰
    stats = fetcher.cleanup_old_data(retention_days=90)
    
    if stats:
        for etf, info in stats.items():
            print(f"\n{etf}: åˆ é™¤ {info['deleted_count']} ä¸ªæ–‡ä»¶")
            if info['deleted_files']:
                print(f"  æœ€æ—©: {info['deleted_files'][0]}")
                print(f"  æœ€æ™š: {info['deleted_files'][-1]}")
    else:
        print("\nâœ… æ²¡æœ‰è¿‡æœŸæ–‡ä»¶éœ€è¦åˆ é™¤")


if __name__ == "__main__":
    test_download_history()
